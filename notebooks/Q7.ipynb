{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "weird-young",
   "metadata": {},
   "source": [
    "7.  Large batch size,  for example 1024, is usually preferred when training a model.  However, limited by the memory of GPU(s), we have to set the batch size to a smaller number, for example 16.  By accumulating the gradients for several steps, for example 64, we can train the model equally with a large batch size, 16*64 = 1024, using a small GPU.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "confident-richardson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms as T\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "interested-disease",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.MNIST('./data/', train=True, download=False, \n",
    "                                    transform=torchvision.transforms.Compose([\n",
    "                                              torchvision.transforms.ToTensor(),    \n",
    "                                              torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                         ]))\n",
    "                                        \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "superb-electron",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.MNIST('./data/', train=False, download=False,\n",
    "                                    transform=torchvision.transforms.Compose([\n",
    "                                              torchvision.transforms.ToTensor(),    \n",
    "                                              torchvision.transforms.Normalize((0.1307,), (0.3081))\n",
    "                                         ]))\n",
    "testloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adaptive-member",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = enumerate(testloader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "example_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "animated-confirmation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "danish-guard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "#         self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "#         self.conv2_drop = nn.Dropout2d()\n",
    "#         self.fc1 = nn.Linear(320, 50)\n",
    "#         self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "#         x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "#         x = x.view(-1, 320)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.dropout(x, training=self.training)\n",
    "#         x = self.fc2(x)\n",
    "#         return F.log_softmax(x)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "prostate-scout",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "LR = 0.05 \n",
    "MOMENTUM = 0.5\n",
    "optimizer = torch.optim.SGD(network.parameters(), lr=LR, momentum=MOMENTUM)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# criterion = torch.nn.functional.nll_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "million-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 3\n",
    "log_interval = 1000\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(trainloader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "rental-twelve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "           )"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "toxic-creator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model=network, train_loader=trainloader, num_epochs = 1, gradient_accumulation_steps = 4):\n",
    "    \n",
    "    # Training the model\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        for steps, (image, labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "#             images = Variable(image.view(-1, 28*28))\n",
    "#             labels = Variable(labels)\n",
    "            \n",
    "\n",
    "            #################  Start your code ################################\n",
    "            \n",
    "            output = model(image)                                  # 1.forward pass\n",
    "            #loss = torch.nn.functional.nll_loss(output, labels)    # 2. compute loss function\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()                                        # 3. Backward pass\n",
    "            optimizer.step()                                       # 4. Optimizer step\n",
    "            \n",
    "            if steps % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format( \\\n",
    "                    num_epochs, steps * len(image), len(trainloader.dataset), \\\n",
    "                    100. * steps / len(trainloader), loss.item())) \n",
    "            \n",
    "      \n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format( \\\n",
    "                num_epochs, steps * len(image), len(trainloader.dataset), \\\n",
    "                100. * steps / len(trainloader), loss.item()))          \n",
    "            #################  End your code ################################\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "challenging-roads",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.316047\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.279748\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.474514\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.052040\n",
      "Train Epoch: 1 [59984/60000 (100%)]\tLoss: 0.006727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "collectible-malaysia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2(model=network, train_loader=trainloader, num_epochs = 1, gradient_accumulation_steps = 4):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        for steps, (image, labels) in enumerate(train_loader):\n",
    "            # model.train()\n",
    "#             images = Variable(image.view(-1, 28*28))\n",
    "#             labels = Variable(labels)\n",
    "            \n",
    "            #################  Start your code ################################\n",
    "            \n",
    "            output = model(image)                                  # 1. forward pass\n",
    "            # loss = torch.nn.functional.nll_loss(output, labels)    # 2. compute loss function\n",
    "            loss = criterion(output, labels)\n",
    "            loss = loss/gradient_accumulation_steps                # 3. normalize loss\n",
    "            loss.backward()                                        # 4. Backward pass\n",
    "            \n",
    "            if steps % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format( \\\n",
    "                    num_epochs, steps * len(image), len(trainloader.dataset), \\\n",
    "                    100. * steps / len(trainloader), loss.item())) \n",
    "            \n",
    "            if (steps + 1) % gradient_accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()         \n",
    "                \n",
    "            #################  End your code ################################\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "widespread-complaint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.570432\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.040131\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.113665\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.049735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-contents",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-referral",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
